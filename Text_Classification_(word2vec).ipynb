{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccqnh5hN7rMY",
        "outputId": "e06b09cd-b1dd-47fa-a619-309cc76f94d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_RzATBg7XOT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc8b381a-628f-4cb7-d444-58e48d2fb80e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "# importing the dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gensim\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk import sent_tokenize\n",
        "from gensim.utils import simple_preprocess"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/IMDB Dataset.csv', engine='python', on_bad_lines='skip')"
      ],
      "metadata": {
        "id": "zwidxAaO715p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "story = []\n",
        "for doc in df['review']:\n",
        "  raw_data = sent_tokenize(doc)\n",
        "  for data in raw_data:\n",
        "    story.append(simple_preprocess(data))"
      ],
      "metadata": {
        "id": "rt5ovFhyqFJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = gensim.models.Word2Vec(\n",
        "    window=10,\n",
        "    min_count=2\n",
        ")"
      ],
      "metadata": {
        "id": "GCGUF6feq1kS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building the vocab\n",
        "model.build_vocab(story)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYwas4gxwRcF",
        "outputId": "83b641e5-5c75-4f81-9b42-345c37796240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "model.train(story,total_examples=model.corpus_count,epochs=model.epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHLNSJALwVrv",
        "outputId": "c400d093-45f1-4fe2-ad80-7aa0ddd844e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29554651, 38938590)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = model.wv.index_to_key"
      ],
      "metadata": {
        "id": "9ppgRfZtwtsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaMfnoEXxAMG",
        "outputId": "52ab410d-7cbe-483a-c67a-6e6f26613ab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53927"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating vector for review\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "def review_vector(doc_text):\n",
        "  # Preprocess the document text to match the vocabulary's format\n",
        "  processed_words = simple_preprocess(doc_text)\n",
        "\n",
        "  # Filter words that are present in the vocabulary 'y'\n",
        "  valid_words = [word for word in processed_words if word in y]\n",
        "\n",
        "  if valid_words:\n",
        "    # If there are valid words, get their vectors and compute the mean\n",
        "    return np.mean(model.wv[valid_words], axis=0)\n",
        "  else:\n",
        "    # If no valid words are found, return a zero vector\n",
        "    # model.wv.vector_size provides the dimension of the word vectors\n",
        "    return np.zeros(model.wv.vector_size)"
      ],
      "metadata": {
        "id": "by80vfyexCHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_vector(df['review'].values[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_dbEanE0edr",
        "outputId": "18ec7fde-30c9-439c-9b31-7440703f243c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.28659683,  0.88581485, -0.08205818, -0.42676416,  0.38880762,\n",
              "       -0.6727667 , -0.25117776, -0.1144669 ,  0.2651066 ,  0.01673012,\n",
              "       -0.08697987, -0.2825848 , -0.17028204,  0.1477451 ,  0.51579607,\n",
              "        0.67909986,  0.35835484,  0.26040483,  0.16170439,  0.09806266,\n",
              "        0.71607333,  0.06991914, -0.11449487,  0.13343006, -0.19123071,\n",
              "        0.7869586 , -0.13060325,  0.31789944, -0.29927224, -0.34662664,\n",
              "        0.11818077,  0.24210607,  0.46426824, -0.40049437,  0.04259898,\n",
              "       -0.4837816 ,  0.29123306, -0.2873268 , -0.19112907, -0.14346123,\n",
              "        0.21546656,  0.0904894 ,  0.21774176,  0.05686488,  0.40206844,\n",
              "        0.42473644,  0.21390648, -1.0006633 , -0.11376081,  0.56735754,\n",
              "        0.50518274,  0.20489798,  0.05028726, -0.13582946, -0.42081952,\n",
              "       -0.27628195,  0.09958383,  0.29870653, -0.05231849, -0.33009142,\n",
              "       -0.47023845, -0.17177308,  0.06023604,  0.5568253 , -0.41920486,\n",
              "       -0.71939826,  0.09909087, -0.10049833,  0.6291242 ,  0.49582514,\n",
              "       -0.46947944, -0.3323042 , -0.02466867, -0.33818555,  0.11306435,\n",
              "       -0.42661384,  0.22361974, -0.443366  , -0.02836919, -0.15867175,\n",
              "       -0.03818085,  0.09992163,  0.21880992,  0.14123367, -0.03426313,\n",
              "        0.18657951, -0.28845745,  0.54837483, -0.30391848, -0.30756828,\n",
              "        0.14573109, -0.10279685,  0.3769333 , -0.6585293 , -0.23755226,\n",
              "        0.10602002,  0.03310312,  0.60839486, -0.2769009 ,  0.16649666],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tdqm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tW0dWCA3t9Y",
        "outputId": "910fd2e9-eefc-4ce4-8059-fe70c1796266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tdqm in /usr/local/lib/python3.12/dist-packages (0.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from tdqm) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "x = []\n",
        "for doc in tqdm(df['review'].values):\n",
        "  x.append(review_vector(doc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVkwKgKt0pBL",
        "outputId": "27ca85b4-a401-4fa1-d1e3-5144bc5e550d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 34831/34831 [01:14<00:00, 467.81it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array(x)"
      ],
      "metadata": {
        "id": "9WQtwAby3r_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx9hHSZI4cdr",
        "outputId": "e5a9ece1-b494-4005-df77-bd97ec6d9c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34831, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(df['sentiment'])"
      ],
      "metadata": {
        "id": "wU9oSP9J_4Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=1)"
      ],
      "metadata": {
        "id": "ucQjxiMgAEyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix"
      ],
      "metadata": {
        "id": "qcpEFWadCX9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using GaussianNB algo\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(x_train,y_train)\n",
        "y_pred = gnb.predict(x_test)\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzQGGAEZAw3t",
        "outputId": "68ae1f5b-9a8c-408a-9adb-155612940026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7238409645471509"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using randomforest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(x_train,y_train)\n",
        "y_pred2 = rf.predict(x_test)\n",
        "accuracy_score(y_test,y_pred2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cNajjPNCsP_",
        "outputId": "c1abe85c-ebc6-4a67-bb4c-2e1faf8c7530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8078082388402469"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# by using GaussianNB algo we get accuracy of 72%\n",
        "# and by using randomforest model we get accuracy of 80%"
      ],
      "metadata": {
        "id": "y9HGaVE9DB2i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}